{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import os\n",
    "#import ntpath\n",
    "import sys\n",
    "from requests import get, post\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paste your credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = r\"https://************.cognitiveservices.azure.com/\" ### paste your resource details (obtained from Azure portal)\n",
    "apim_key = \"***********\" ###  paste your keys\n",
    "\n",
    "\n",
    "invoiceFullFilename=\"*.pdf\" #### path to your invoice file (It can be pdf, jpd, png, tiff etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyzeInvoice(filename):\n",
    "    invoiceResultsFilename = filename + \".invoice.json\"\n",
    "\n",
    "    # do not run analyze if .invoice.json file is present on disk\n",
    "    if os.path.isfile(invoiceResultsFilename):\n",
    "        with open(invoiceResultsFilename) as json_file:\n",
    "            return json.load(json_file)\n",
    "\n",
    "    post_url = endpoint + \"/formrecognizer/v2.1/prebuilt/invoice/analyze\"\n",
    "    headers = {\n",
    "        # Request headers\n",
    "        'Content-Type': 'application/pdf', ### if pdf use this. if it is image format change to 'image/jpeg', 'image/png' or 'image/tiff' depending on your case\n",
    "        'Ocp-Apim-Subscription-Key': apim_key,\n",
    "    }\n",
    "\n",
    "    params = {\n",
    "        \"includeTextDetails\": True\n",
    "    }\n",
    "\n",
    "    with open(filename, \"rb\") as f:\n",
    "        data_bytes = f.read()\n",
    "\n",
    "    try:\n",
    "        resp = post(url = post_url, data = data_bytes, headers = headers, params = params)\n",
    "        if resp.status_code != 202:\n",
    "            print(\"POST analyze failed:\\n%s\" % resp.text)\n",
    "            return None\n",
    "        print(\"POST analyze succeeded: %s\" % resp.headers[\"operation-location\"])\n",
    "        get_url = resp.headers[\"operation-location\"]\n",
    "    except Exception as e:\n",
    "        print(\"POST analyze failed:\\n%s\" % str(e))\n",
    "        return None\n",
    "\n",
    "    n_tries = 50\n",
    "    n_try = 0\n",
    "    wait_sec = 6\n",
    "\n",
    "    while n_try < n_tries:\n",
    "        try:\n",
    "            resp = get(url = get_url, headers = {\"Ocp-Apim-Subscription-Key\": apim_key})\n",
    "            resp_json = json.loads(resp.text)\n",
    "            if resp.status_code != 200:\n",
    "                print(\"GET Invoice results failed:\\n%s\" % resp_json)\n",
    "                return None\n",
    "            status = resp_json[\"status\"]\n",
    "            if status == \"succeeded\":\n",
    "                print(\"Invoice analysis succeeded.\")\n",
    "                with open(invoiceResultsFilename, 'w') as outfile:\n",
    "                    json.dump(resp_json, outfile, indent=4)\n",
    "                return resp_json\n",
    "            if status == \"failed\":\n",
    "                print(\"Analysis failed:\\n%s\" % resp_json)\n",
    "                return None\n",
    "            # Analysis still running. Wait and retry.\n",
    "            time.sleep(wait_sec)\n",
    "            n_try += 1     \n",
    "        except Exception as e:\n",
    "            msg = \"GET analyze results failed:\\n%s\" % str(e)\n",
    "            print(msg)\n",
    "            return None\n",
    "\n",
    "    return resp_json\n",
    "\n",
    "def parseInvoiceResults(resp_json):\n",
    "    docResults = resp_json[\"analyzeResult\"][\"documentResults\"]\n",
    "    invoiceResult = {}\n",
    "    for docResult in docResults:\n",
    "        for fieldName, fieldValue in sorted(docResult[\"fields\"].items()):\n",
    "            valueFields = list(filter(lambda item: (\"value\" in item[0]) and (\"valueString\" not in item[0]), fieldValue.items()))\n",
    "            invoiceResult[fieldName] = fieldValue[\"text\"]            \n",
    "            if len(valueFields) == 1:\n",
    "                print(\"{0:26} : {1:50}      NORMALIZED VALUE: {2}\".format(fieldName , fieldValue[\"text\"], valueFields[0][1]))\n",
    "                invoiceResult[fieldName + \"_normalized\"] = valueFields[0][1]\n",
    "            else:\n",
    "                print(\"{0:26} : {1}\".format(fieldName , fieldValue[\"text\"]))\n",
    "    print(\"\")\n",
    "    return invoiceResult\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_json = analyzeInvoice(invoiceFullFilename)\n",
    "if (resp_json is not None):\n",
    "    invoiceResults = parseInvoiceResults(resp_json)\n",
    "    invoiceResults[\"FullFilename\"] = invoiceFullFilename\n",
    "    #invoiceResults[\"Filename\"] = invoiceFilename\n",
    "    #writer.writerow(invoiceResults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resp_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "for read_result in resp_json[\"analyzeResult\"][\"readResults\"]:\n",
    "    # print(\"Page No:%s\" % read_result[\"page\"])\n",
    "    print(\"--------------Page %d: Extracted OCR---------------\" % read_result[\"page\"])\n",
    "    for line in read_result[\"lines\"]:\n",
    "        print(line[\"text\"])\n",
    "\n",
    "for pageresult in resp_json[\"analyzeResult\"][\"pageResults\"]:\n",
    "    # print(\"Page No:%s\" % pageresult[\"page\"])\n",
    "    #if pageresult[\"page\"] == 4:\n",
    "   \n",
    "    for table in pageresult['tables']:\n",
    "        print(\"--------------Page %d: Extracted table---------------\" % pageresult[\"page\"])\n",
    "        # print(\"-------------------Extracted Table-------------------\")\n",
    "        print(\"No of Rows: %s\" % table[\"rows\"])\n",
    "        print(\"No of Columns: %s\" % table[\"columns\"])\n",
    "        tableList = [[None for x in range(table[\"columns\"])] for y in range(table[\"rows\"])] \n",
    "        for cell in table['cells']:\n",
    "            tableList[cell[\"rowIndex\"]][cell[\"columnIndex\"]] = cell[\"text\"]\n",
    "        #print(\"new table\" , tableList)\n",
    "        df = pd.DataFrame.from_records(tableList)\n",
    "        display(df)\n",
    "        #print(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
